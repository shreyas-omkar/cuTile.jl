module cuTile

# Bytecode infrastructure
include("bytecode/encodings.jl")

# Compiler infrastructure
include("compiler/codegen.jl")

# Public API
export emit_tileir, compile
export Tile

#=============================================================================
 API Types
=============================================================================#

"""
    Constant{T}

Marker type for compile-time constant values.
"""
struct Constant{T}
    value::T
end

Base.convert(::Type{Constant{T}}, x::T) where T = Constant{T}(x)

"""
    Tile{T, Shape}

Represents a tile of data with element type `T` and static shape `Shape`.
Shape is a tuple of integers representing the tile dimensions.

This is a compile-time abstraction - at runtime in kernel code, tiles are
represented as Tile IR values. The struct exists to enable proper type
inference and operator dispatch.
"""
struct Tile{T, Shape}
    # No runtime fields - this is a phantom type for the compiler
    # The actual data lives in GPU registers during kernel execution

    # Inner constructor that's never actually called at runtime
    function Tile{T, Shape}() where {T, Shape}
        new{T, Shape}()
    end
end

# Type accessors
Base.eltype(::Type{Tile{T, Shape}}) where {T, Shape} = T
Base.eltype(::Tile{T, Shape}) where {T, Shape} = T
tile_shape(::Type{Tile{T, Shape}}) where {T, Shape} = Shape
tile_shape(::Tile{T, Shape}) where {T, Shape} = Shape

#=============================================================================
 Tile Arithmetic
=============================================================================#

# These are stub implementations that the compiler intercepts.
# They return a new Tile with the same shape, enabling proper type inference.

@noinline function tile_add(a::Tile{T, S}, b::Tile{T, S})::Tile{T, S} where {T, S}
    Tile{T, S}()
end

@noinline function tile_sub(a::Tile{T, S}, b::Tile{T, S})::Tile{T, S} where {T, S}
    Tile{T, S}()
end

@noinline function tile_mul(a::Tile{T, S}, b::Tile{T, S})::Tile{T, S} where {T, S}
    Tile{T, S}()
end

# Operator overloads dispatch to the intrinsic functions
Base.:(+)(a::Tile{T, S}, b::Tile{T, S}) where {T, S} = tile_add(a, b)
Base.:(-)(a::Tile{T, S}, b::Tile{T, S}) where {T, S} = tile_sub(a, b)
Base.:(*)(a::Tile{T, S}, b::Tile{T, S}) where {T, S} = tile_mul(a, b)

#=============================================================================
 Tile Shape Operations
=============================================================================#

"""
    transpose(tile::Tile{T, (M, N)}) -> Tile{T, (N, M)}

Transpose a 2D tile, swapping its dimensions.
"""
@noinline function transpose(tile::Tile{T, S})::Tile{T, reverse(S)} where {T, S}
    Tile{T, reverse(S)}()
end

#=============================================================================
 GPU Intrinsics (stub implementations for host-side)
=============================================================================#

# Note: These stubs are markers for the compiler to recognize.
# The actual implementations are handled by the compiler which emits Tile IR ops.
#
# We use Base.compilerbarrier(:const, ...) to prevent constant folding while
# allowing other optimizations. This lets us use optimized IR.
# If these reach runtime (not compiled), they error with a clear message.

"""
    bid(axis) -> Int32

Get the block ID along the given axis (0=x, 1=y, 2=z).
In kernel code, this is compiled to GetTileBlockIdOp.
"""
@noinline bid(axis::Integer)::Int32 = Base.inferencebarrier(zero(Int32))

"""
    num_blocks(axis) -> Int32

Get the grid size along the given axis (0=x, 1=y, 2=z).
In kernel code, this is compiled to GetNumTileBlocksOp.
"""
@noinline num_blocks(axis::Integer)::Int32 = Base.inferencebarrier(zero(Int32))

"""
    load(ptr, index, shape::NTuple{N, Int}) -> Tile{T, shape}

Load a tile from a pointer at the given index with the specified shape.
In kernel code, this is compiled to LoadViewTkoOp.

Returns a `Tile{T, Shape}` where T is the pointer element type and Shape
is the compile-time constant shape tuple.
"""
@noinline function load(ptr::Ptr{T}, index, shape::NTuple{N, Int}) where {T, N}
    # The shape must be a compile-time constant for the return type
    Tile{T, shape}()
end

"""
    store(ptr, index, tile::Tile) -> Nothing

Store a tile to a pointer at the given index.
In kernel code, this is compiled to StoreViewTkoOp.
"""
@noinline function store(ptr::Ptr{T}, index, tile::Tile{T})::Nothing where T
    # donotdelete prevents the optimizer from eliminating this call
    # even though it has no observable effects in Julia
    Base.donotdelete(ptr, index, tile)
    nothing
end

"""
    compile(f, argtypes; name=nothing, sm_arch="sm_100", opt_level=3) -> Vector{UInt8}

Compile a Julia kernel function to CUBIN.
"""
function compile(@nospecialize(f), @nospecialize(argtypes);
                 name::Union{String, Nothing}=nothing,
                 sm_arch::String="sm_100",
                 opt_level::Int=3)
    tile_bytecode = emit_tileir(f, argtypes; name)

    input_path = tempname() * ".tile"
    output_path = tempname() * ".cubin"

    try
        write(input_path, tile_bytecode)
        run(`tileiras $input_path -o $output_path --gpu-name $sm_arch -O$opt_level`)
        return read(output_path)
    finally
        rm(input_path, force=true)
        rm(output_path, force=true)
    end
end

end # module cuTile
